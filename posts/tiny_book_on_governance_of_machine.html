<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Governance of Machine</title>
    <style>
        /* Define a variable for the font size */
        :root {
            --font-size: 1.25rem;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            color: #1a1a1a;
            background-color: #ffffff;
            padding: 1rem;
        }

        .container {
            max-width: 38em;
            margin: 0 auto;
            padding: 1rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 2rem;
            line-height: 1.2;
        }

        #story p {
            font-size: var(--font-size);
            margin-bottom: 1.5rem;
        }
        
        /* List styling */
        #story ul, #story ol {
            font-size: var(--font-size);
            margin-bottom: 1.5rem;
            margin-left: 2rem;
        }
        
        /* All list items get the same spacing */
        #story li {
            margin-bottom: 0.65rem;
        }
        
        /* Add more space after a list ends inside a top-level list item */
        #story > ul > li > ul,
        #story > ul > li > ol,
        #story > ol > li > ul,
        #story > ol > li > ol {
            margin-bottom: 0.9rem;
        }

        /* Nested lists styling */
        #story ul ul, 
        #story ul ol,
        #story ol ul,
        #story ol ol {
            margin-top: 0.5rem;
            margin-bottom: 1.6rem;
        }

        @media (prefers-color-scheme: dark) {
            body {
                background-color: #1a1a1a;
                color: #f0f0f0;
            }
        }

        @media (max-width: 600px) {
            body {
                padding: 0.5rem;
            }

            .container {
                padding: 0.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            #story p, 
            #story ul,
            #story ol {
                font-size: var(--font-size);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="story">
<h1>The Tiny Book on the Governance of Machine</h1>
<p>No one wants to read 50 pages on governance. This book is built to be read in parts; pick the parts you’re interested in.</p>
<p>Want a primer on AI? Start with .</p>
<p>Already up to speed on AI and understand the risks? Jump straight to . </p>
<p>Just want to read some new ideas in AI governance? Jump to .</p>
<p>Only have 30 seconds? Read the TL;DR</p>
<br>
<h1>TL;DR</h1>
<ul>
  <li><strong>AI changes what we need from governance</strong></li>
  <ul>
    <li>Societies that allow for freedom and maximum human flourishing aren’t easy to build</li>
    <li>Ours took thousands of years of trial and error and is still a work in progress</li>
    <li>What allows a society to function depends strongly on the details of its members: us humans</li>
    <li>Introducing AI will completely change all of those details</li>
    <li>Because of that, we must rethink society if we want it to be resilient to the arrival of AI</li>
  </ul>
  <li><strong>There are many risks we’ll face, and some risks aren’t yet being discussed</strong></li>
  <ul>
    <li>In particular, the risk of concentration of power and dictatorship is extreme with the full power of AI automation</li>
    <li>Without changes, dictatorships are a default outcome of AI. And it will be increasingly hard for us to resist it the later we act</li>
    <li>We must evolve our governance <em>before</em> strong AI arrives, or we may not have any power left as citizens to fix it <em>after</em></li>
    <li>Humans alone won’t be able to oversee leaders empowered by AI</li>
  </ul>
  <li><strong>AI-powered governance of AI</strong></li>
  <ul>
    <li>Instead, we must leverage AI itself to become part of the checks and balances on how government and industry wield AI</li>
    <li>Passing laws is necessary but not sufficient</li>
    <li>We must enshrine the oversight inside the mechanisms of culture and government, and we must do it while we still have human-based trust in human institutions</li>
  </ul>
  <li><strong>We all are part of this</strong></li>
  <ul>
    <li>AI is the most important event in our life time, but the outcome is not yet written</li>
    <li>We all own the conversation for what we want the future to be</li>
  </ul>
</ul>
<h1>Intro</h1>
<p>We assume that machines will achieve human level intelligence. We assume they will exceed it. We assume that they will have ethics, aligned to a human or group of humans.</p>
<p>Then the question remains: which human or group of humans. To which other humans are those humans accountable and by what means. Where does the demos in democracy sit?</p>
<p>The ambition of people leads to cathedrals and death camps. Prosperity and war. Governance is how we harness our collective ambitions to aim for the good. It's not just laws, it's culture, norms, and expectations we place upon ourselves, our neighbors, and our children. It's the combined wisdom of society for how we can stand both free and together to march forward.</p>
<p>There aren’t easy answers for what governance should look like, only tradeoffs and complex second order dynamics. Should we empower a strong leader to move rapidly, hoping they won’t abuse their position? Or should we create a slow moving bureaucracy, resilient to corruption but unresponsive to changing needs? Outside of government we must answer similar questions for our communities and companies. How much power? How much oversight?</p>
<p>The US has a mixture of answers to these questions. We allow CEOs to be board elected dictators of companies. With it can come great speed, vision, coordination, or rapid failure. There are checks though: The board. The market. Employees can vote with their feet, or the implied threat of them. Regulation limits the most extreme excesses and the worst tragedy of the commons. But even still, a successful CEO can amass so much wealth as to pose unacceptable danger, as we saw with the robber barons. So we further limit what wealth can achieve: bribes are illegal and we curtail the ability to buy politicians outright. Failing to curtail the abilities of wealth itself, we curtail the maximum accumulation of wealth by breaking up monopolies. We invest in common goods like education so that others can rise up and build their own wealth, to counter the entrenched wealth of the past.</p>
<p>We elect a president of a strong federal government to have time limited, broad authority. With checks. There’s only ever one president at a time, so there is no free market of presidents, so we can’t allow outright failure when it might mean the end of democracy. So we prevent the use of power to further seek power, such as to influence an election. We empower Congress and the judiciary to prevent the executive from granting itself more power and creating a runaway process toward dictatorship.</p>
<p>Implicit but just as important is culture. The American tradition of democracy and standing against tyrants. The President’s cabinet is a set of Americans beholden to this culture, upheld by social pressure from their friends, family, and community. The federal agencies they oversee are composed of millions of Americans, allowing a million opportunities for American culture to uphold itself. A million opportunities to thwart a would-be tyrant. Once we fully automate government, where will these guardrails come from?</p>
<p>What mechanism will ensure government is for the people when it’s no longer of the people and by the people?</p>
<p>We’re rapidly approaching AI strong enough to automate our government, without understanding how we’ll hold government accountable with that new power. It may prove <em>impossible</em> to control government after we give it this power, if we haven’t put controls in place beforehand. There is a path dependence to our future, and timing is a critical variable:</p>
<p>You don't grant Caesar an army to conquer Gaul for Rome until <em>after</em> you are confident you can govern Caesar. The Rubicon is not a sufficient form of governance definition, no matter how strong the norms not to march across it are. In this sense we see that governance is a form of alignment, where we want helpful results for society (build Rome!) while minimizing the harmful outcomes (don’t conquer Rome!). This abstraction applies then to machine, humans, organizations, and machine powered organizations. </p>
<p>There aren't easy answers, despite the allure of simple ideologies and absolutisms. Even today our governance is imperfect, and we risk devolution and dictatorship at all turns without constant vigilance and adaption. What was needed to govern well the Romans is not what is needed to govern well today. And it’s almost certainly not what’s needed to govern a human-machine civilization tomorrow. And tomorrow may be very soon.</p>
<p>The core question of governance is how to govern <em>intelligences</em>, human or otherwise: collections of forces that can achieve what they seek, can win more power, can cooperate, compete, and destroy. Governance is a set of yes’s and no’s: yes compete this way, no don’t destroy this way, such that the citizens mutually benefit and consolidation of power into dictators is prevented. And the dangers of power abound.</p>
<p>A glib history of governance: governance too weak can lead to hard times and dictators; too strong can lead to hard times and dictators. And there isn’t a simple line between weak and strong. There is no simple compromise, and compromise itself is only sometimes the answer.</p>
<p>Machines will likely enumerate a range of intelligences, requiring a range of governance types. With that lens humans are a special case of governing intelligence. But we further see that a society of humans and machines combined is another case again, and is likely the future we’ll be in.</p>
<p>The question of how to govern machine is thus a question of how to govern man. What social compact must we craft so that an aggregate society of diverse intelligences is a net good for those intelligences, and a net good for us in particular.</p>
<p>Thousands of years have been spent on the question of human governance. Millions of thinkers. Countless debates. Dense treatise. Horrible wars.</p>
<p>The question touches the nature of our existence. What world do we want to live in?</p>
<p>The governance of machine poses an equally profound question. We won't have a thousand years to arrive at good answers. We can't afford the deaths of past wars to settle disagreements. We have little time.</p>
<p>But we must find an answer.</p>
<h1>Contents</h1>
<p>The debate for how to govern a human-machine society may prove the greatest in our lifetime, perhaps as important as the founding debates around modern democracies themselves. Every one of us has a role to play: to engage in this debate, to shape it, to fight for governance that lifts up mankind and allows this new age that’s upon us to be a noble one, not a dark one.</p>
<p>In this tiny book we’ll cover the basics:</p>
<ul>
  <li>Why is this important, aren’t there bigger problems to solve?</li>
  <li>How does our current civilization work, and what will stop working once we have AI?</li>
  <li>What does the current political, cultural, and power landscape look like as it relates to AI?</li>
  <li>What might a human-machine society look like, what might governance look like, and how can we leverage AI to make it possible?</li>
</ul>
<h1>Why</h1>
<p>Some might say, “One problem at a time.”</p>
<p>First, let’s build the machine. This is hard enough.</p>
<p>Then, let’s make sure it’s safe. This is hard enough.</p>
<p>Finally, let’s see how to integrate it into society. Let’s only then craft a world with AI that’s still a world for humans, with all the challenges and upheavals that will take.</p>
<p>Depending on how spaced apart these events are, that’s a reasonable position. 50 years ago certainly there was enough time to focus on the first problem only. 5 years ago perhaps it was fair to focus only on the hard problem of making AI safe. Today, these three events may all happen in the next few years. If so, practically, we can’t wait to solve each problem one by one. There won’t be enough time to do it right. Worse, if we build controllable AI but don’t know how to govern that new human-machine world, there may not be any way to prevent the worst outcomes of concentration of power and the rise of durable dictatorships. The path to a good human-machine world very likely requires taking the correct actions <em>leading up to</em> the arrival of strong AI, <strong>even if</strong> we have solved the problem of ensuring the AI is safe.</p>
<p>There is a path dependence, and <strong><em>our actions today matter more than our actions tomorrow</em></strong>.</p>
<p>If you’re an AI researcher, today your voice matters, tomorrow you will be automated and will lose your currency. If you’re a government employee, today your voice matters, tomorrow you will be automated. If you’re a voting citizen, today your vote matters, tomorrow it might not be possible to vote out an automated government dictatorship. If you’re any person at all, of any walk of life or nation, today your actions impact the shared culture of humanity, which helps pressure and guide the actions of every other person. Tomorrow, we may live in a world where no amount of cultural pressure matters. Your actions matter today, use them to ensure they still matter tomorrow.</p>
<p>How soon will strong AI arrive? We won’t spend time analyzing timelines here. There are great discussions about this, it’s increasingly important, but it’s overall a well trod area. What’s not well trod is what the world should look like <em>after</em>. After we’ve built and aligned the machine. And, anyway, the timeline discussions are changing rapidly, anything we write here will likely be outdated before this is published or before you read this. Regardless of timelines, whether we have two years or ten years, there isn’t enough time. We have to prepare now.</p>
<p>Nonetheless, keep engaging in timeline discussions. Keep an array of timelines in your mind. The future is a portfolio of risks and investments. With great uncertainty we should maintain wide error bars and consider many outcomes. Our discussions on governance here should be informed by changing timelines in practice. We’ll discuss proposals that will be good or bad depending on timelines; meaning a bad proposal today may be good tomorrow, and the reverse too. Good risk management means <em>sometimes</em> charging forward boldly, it’s sometimes too risky to be timid. Good risk management means <em>sometimes</em> hedging. Picking correctly isn’t a matter of principle, it’s a matter of skill applied to ever changing details.</p>
<p>As you consider proposals here and elsewhere, if you dislike them, ask yourself if it’s because you disagree with the implied timelines. If so, say out loud, “I don’t think X will happen soon, therefore the cost of Y is too high and I’m willing to risk Z.” Often this is correct. But not always. Say it out loud.</p>
<p>If you like or dislike a proposal, ask yourself if it’s because it matches your ideology, rather than a calculus on outcomes. If so, say out loud, “I prefer to live in a world with X as a principle, even if the worst form of Y outcome results.”</p>
<p>Often this too is correct and good. Speak clearly to yourself and others when you think this. There’s no good in securing a future where we’ve negotiated away our most cherished rights.</p>
<p>What we’re seeing today in AI research is that one of the hardest problems in AI capabilities is teaching the machine to self reflect accurately. Teaching it to recognize when it’s uncertain, when it’s made an unstated assumption, when it’s caught in a doom loop and can’t break free. Improving introspection and self-mastery is key to improving an AI’s ability. Ironically, we know this is true for us humans as well. The low quality of much of our discourse echoes the same reasoning failures we see from AIs today: failure to generalize, failure to highlight unstated assumptions, failure to rethink from first principles and not just pattern match, failure to recognize our own mistakes and self-correct. </p>
<p>Failure to be honest: to yourself first, then to others.</p>
<p>Because timelines are short, we need to compress a thousand years of governance debate into just a few years. We can do that, but only if we raise the level of discourse.</p>
<p>In the early days of the United States there were great debates on governance. What makes a resilient republic? Volumes were written, dissected, prosecuted. The greatest minds of the time partook. Society as a whole partook. The path forward wasn’t clear, and so we embraced the uncertainty and dug into the hard work of debate to form a more perfect democracy. This took years, it took war, and we are still debating today. But a resilient democracy has endured 250 years because of it.</p>
<p>That democracy, and many others like it, has been the bedrock that’s supported science, technology, social progress, and all of society’s many investments. Investments that have led to the incredible human flourishing we have today. By the standards of any other time in human history, today is the best day. And it’s built upon our modern governance. We know that good governance is the first requirement to prosperity. We know it through the thousand failed experiments, failed governments, failed nations, failed societies, that have caused untold suffering. We know it through the veritable paradise we enjoy today.</p>
<p>The details of good governance depend on the details of what humanity is. If humanity were different, governance would be different. Machine is different from human, and will need different governance. The incentives at play, the instincts, the interplay between dynamics, the form of self-correcting guardrails, everything will be different. Sometimes obviously so. Sometimes subtly.</p>
<p>We won’t get it perfectly right, but we must get it right enough. Right enough to fortify democracy for the human-machine age.</p>
<p>This is all we’ll say on the why. The rest of this writing we’ll focus on the hard question of what. Where we’ll finish by the end will barely constitute an introduction. The rest will be up to you.</p>
<p>Let's begin.</p>
<h1>Complexity and Iterative Design</h1>
<p>Civilization is complex. To study complex systems we often make simplifying assumptions.</p>
<p>When we build models for how fluids like water and air behave, we wash away the details of H2O molecules or air molecules and arrive at a higher level theory of how water and air moves, described by relatively simple equations like Navier Stokes. The success of computational fluid dynamics vindicates this approach, along with the safety of aircraft and multitudes of other technologies predicated on our correct-enough understanding of fluids like air. Even in these simplified theories we see complexity continue to counter us. Fluids become turbulent and enter chaotic regimes where it’s not just our current models that lose predictive powers, rather all models must lose their power.</p>
<p>Civilization is more complex. Models that average over the human molecules are alluring but fraught, in fiction and reality. Economics treats humans like a smooth fluid, averaging out our uniqueness and quirks. The truth is these quirks matter. The outliers matter — at an individual and global level. We may still debate the great man theory of history, but there’s no doubt that Nazi Germany would have played out differently without Adolf Hitler. And thus likely the entire history of the 21st century.</p>
<p>Still, there are limits on how much a single human can impact the world. We have limited lifespans and limited ability to change ourselves. With AI this gets more complex. AI’s that can self-modify will create a world that is even more sensitive to initial conditions and the path of individual molecules.</p>
<p>Civilization is a system with emergent turbulence at the largest scale, but where the path of individual molecules also matters at the smallest scale. In systems theory this is the hardest type of <em>multi-scale</em> system to predict and engineer for. With AI, we will be introducing a further complication: changing the dynamics of the molecules themselves <em>on a continual basis</em>. The AI molecule will change constantly, will individually shape the outcomes of the world, and will be shaped by the global process as well. A complex system where the small scale matters, the large scale matters, and where each scale can rewrite the rules of the other scale every day.</p>
<p>Managing fluids is much easier, but we can still learn from it. We see where there is turbulence and where our models fail, so we engineer our planes to avoid those territories. Our theories remain imperfect and planes crash, so we iterate and refine both our theories and engineering practices. Like all complex engineering processes, we follow an iterative design philosophy. We’ve iterated on civilization and governance for thousands of years. We’ve crashed many civilizations, built many wrong theories of governance, but through it all we’ve iterated and arrived at a beautiful, complicated, impossible creation: the world we see today.</p>
<p>To build the world of tomorrow we’ll need to use all our approaches:</p>
<ul>
  <li>a theorist’s dissection of why civilization works, especially the implicit dynamics often overlooked</li>
  <li>a willingness to abandon and remake our theory, and to hold multiple competing theories at once</li>
  <li>an engineering mindset to steer away from where we know our theories fail</li>
  <li>a designer’s mindset to iterate quickly as reality pulls your planes from the sky</li>
</ul>
<p>This is how we’ll forge a resilient system.</p>
<p>Let’s start with the first approach: to understand what works today. In particular, what are the hidden, implicit forces that hold civilization together that may disappear in an automated world.</p>
<h1><s>Implicit</s> Guardrails</h1>
<p>Link out to </p>
<h1>By any other name</h1>
<p>Link out to  and/or </p>
<h1>Rapid fire governance</h1>
<p><h1>An exponential, if you can keep it</h1>
<p><br>
<br>
<p>Appendix</p>
<p>
        </div>
    </div>
</body>
</html>