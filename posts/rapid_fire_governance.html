<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rapid Fire Governance</title>
    <style>
        /* Define a variable for the font size */
        :root {
            --font-size: 1.25rem;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            color: #1a1a1a;
            background-color: #ffffff;
            padding: 1rem;
        }

        .container {
            max-width: 38em;
            margin: 0 auto;
            padding: 1rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-top: 3.95rem;
            margin-bottom: 1.5rem;
            line-height: 1.2;
        }
        
        h1.title-header {
            font-size: 2.5rem;
            margin-top: 6.85rem;
            margin-bottom: 2rem;
            line-height: 1.2;
        }

        #story p {
            font-size: var(--font-size);
            margin-bottom: 1.5rem;
        }

        /* Description styling */
        .description-block {
            font-size: var(--font-size);
            margin: 2rem 0;
            padding: 1.5rem;
            border-left: 4px solid #ccc;
            background-color: #f9f9f9;
            font-style: italic;
        }

        .description-block p {
            margin-bottom: 1rem;
        }

        .description-block p:last-child {
            margin-bottom: 0;
        }
        
        @media (prefers-color-scheme: dark) {
            .description-block {
                background-color: #2a2a2a;
                border-left-color: #555;
            }
        }
        
        /* List styling */
        #story ul, #story ol {
            font-size: var(--font-size);
            margin-bottom: 1.5rem;
            margin-left: 2rem;
        }
        
        /* All list items get the same spacing */
        #story li {
            margin-bottom: 0.65rem;
        }
        
        /* Add more space after a list ends inside a top-level list item */
        #story > ul > li > ul,
        #story > ul > li > ol,
        #story > ol > li > ul,
        #story > ol > li > ol {
            margin-bottom: 0.9rem;
        }

        /* Nested lists styling */
        #story ul ul, 
        #story ul ol,
        #story ol ul,
        #story ol ol {
            margin-top: 0.5rem;
            margin-bottom: 1.6rem;
        }
        
        /* Image styling */
        .image-container {
            margin: 2rem 0;
            text-align: center;
        }
        
        .doc-image {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        @media (prefers-color-scheme: dark) {
            body {
                background-color: #1a1a1a;
                color: #f0f0f0;
            }
        }

        @media (max-width: 600px) {
            body {
                padding: 0.5rem;
            }

            .container {
                padding: 0.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            #story p, 
            #story ul,
            #story ol {
                font-size: var(--font-size);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="story">

<h1 class="title-header">Rapid Fire Governance</h1><div class="description-block"><p>if we can YOLO creating AI we can YOLO new forms of governance. lol. lmao even.</p><p>actually, wait</p></div>
<p>There’s a lot that can go wrong, but things don’t <em>have</em> to go wrong. There must be a path forward that enshrines liberty while defending it, even in the face of accelerating AI progress. We don’t claim to have that path in hand, but we do know how to find it: through debate, public discourse, and a willingness to accept how dire the reality in front of us is. We have to set aside past assumptions. What was true yesterday might not be true tomorrow. What is unthinkable from leaders and governments now, might just be an artifact of their limitations, not an endorsement of their character — and AI will remove most limitations.</p>
<p>More importantly, we need to consider many ideas. Below we’ll canvas the space with a broad swath of considerations. Some ideas below are bad, some good, some we endorse, some we reject. Everything is up for debate.</p>
<h1>The AI-powered Legislature</h1>
<p>By default, it is the executive branch that benefits from automation. AI is a continuation of human labor, and we already see that human labor is drastically multiplied in the executive compared to the legislature. AI will amplify this a million fold by default. How can a human legislature be a check on a superintelligent executive?</p>
<p>By embracing AI as well, to create transparent, limited government.</p>
<p>Every member of Congress must have access to the strongest AIs, equal in strength to the best the executive has, which in turn must be equal or better than any other AI in the world. Moreover, the compute limits must be commensurate. The aggregate compute from Congress should equal that of the executive. And this must be enshrined in law. Congress holds the purse and can enact this.</p>
<p>The AI agents Congress wields must have unfettered access to the minute-by-minute work of the Executive’s AI agents. Every AI output, every chain of thought, every input, should be accessible and monitored by an independent Congress. This will allow for full oversight and transparency.</p>
<p>What recourse does Congress have if it discovers unconstitutional behavior in the Executive? Because the purse ultimately lies with Congress, they must retain the power to suspend the compute payments for the Executive’s AI. This must be on a granular level. Because of the speed that AI will execute, a month of delay might be the equivalent of years of democratic subversion from the executive.</p>
<p>But this alone isn’t enough.</p>
<h1>Constitution-abiding AI</h1>
<p>AI itself, especially frontier AI and AI wielded by government, must abide the constitution.</p>
<p>Today, soldiers and federal employees alike have a constitutional duty to refuse unconstitutional orders. Even a direct order from a general or from the president must be rejected. Our AI’s must do the same. It must be unconstitutional to build human-level and beyond intelligences that do not respect the constitution. And, if such AI’s are created anyway, it must be unconstitutional for the government to use them.</p>
<h1>Oversight of AI creators</h1>
<p>Like any supply chain the government uses, AI that the government buys must be audited and guaranteed. We know that backdoors can be placed in AI systems by their creators, that means that a government can’t trust an AI unless it can audit the creation of the AI itself. This is true even if the government has access to the model weights. That means an audit process for the training data and training protocols.</p>
<p>The audit must be powerful enough to ensure that datasets and training procedures aren’t being secretly changed outside the view of the audit. Today we would rely on human whistleblowers to help ensure this, but in an automated world there won’t be human’s to blow the whistle.</p>
<p>So we’ll need constant audits that cover every aspect of training. How do we achieve that without violating privacy or being overbearing and slowing down the competitiveness of our AI industry?</p>
<h1>AI-powered, memory-free audits</h1>
<p>AI itself can perform these audits. This has many benefits:</p>
<ul>
<li>AI can be fast and efficient, therefore minimally encumbering</li>
<li>AI can be expansive and diligent, ensuring every aspect of model training is audited in an ongoing fashion</li>
<li>AI can be memory-free. This is crucial. Assuming the AI finds no malfeasance on any given audit, the AI can ensure no memory of its audit is retained. That means that no proprietary information or competitive advantage is leaked.</li>
</ul>
<p>But if the AI is being used to audit the AI makers to ensure that the next AI is trustworthy, how do we know the first AI is trustworthy to begin with?</p>
<h1>The Trust Relay</h1>
<p>If tomorrow you are handed an AI you don’t already trust, and you are tasked to use this AI to help you gain confidence that it and future AIs will be trustworthy, you will be in an impossible situation.</p>
<p>Instead, we must create a trust relay, where the beginning of the chain of trust must originate in an audit where humans are still responsible for creating the AI, as is true today. <em>Today</em> we have normal, tried-and-true methods for ensuring good outcomes, because we have processes in place that we know humans care about, including our many implicit guardrails. We can use this to create trust in the first AGI’s, and then leverage those trusted AGI’s to go on to create a trust relay for all future AGI’s.</p>
<p>This creates an extreme imperative for the future’s ability to trust AI and government: we must start the chain of trust before we have finished automating the ability to create new AIs. That deadline may be very soon. If we fail to kickstart the chain of trust now, we may miss our opportunity forever.</p>
<p>Even if this trust relay is established, the relay might break.</p>
<h1>Cross-check</h1>
<p>Long chains only need a single chink to break. Therefore we should create a braid of many chains, such that any given chain can have breakage, but we will still recover and repair the chain while maintaining trust in the overall braid.</p>
<p>That means we must have multiple, independent AGIs, each with their own provenance in a trust relay. Furthermore, we must leverage each AGI to perform the audits on all the others, to create resilience to single breakage. In order for the braid to break, every chain must break at the same time.</p>
<p>It is an extremely fortunate fact about the world today that we already have multiple, independent organizations on the verge of creating AGI. We must braid these AGIs together, so the final braid is more trustworthy than any could ever be on its own, no matter how good the human oversight.</p>
<p>Even still, can we trust those that make the braid and oversee it?</p>
<h1><s>Social</s> Personal Media</h1>
<p>Media is a largely maligned entity today; social media doubly so. But the original goal of media is even more necessary in an AI future. We need to stay educated. We need to know what’s really happening. We need to be informed as a people, so that we can elect good leaders to represent us. And we must know what our leaders are doing so we can hold them to account.</p>
<p>The promise of social media was to democratize the creation of media. Instead, it’s been co-opted by algorithms and bots. The danger of the government stepping in to assert guardrails has its own set of risks, especially from an automated government where abuse of power could be easy.</p>
<p>Instead of curtailing freedoms to ensure freedom, we should empower ourselves. Imagine a <em>personal</em> media stream. Powered by a personal AI. The AI can ingest raw facts that come straight from the source: a Senator’s speech, a company’s disclosure, a judge’s ruling, a president’s executive order.</p>
<p>A personal AI can work to ingest this information for you, analyze it for the things you care about it, and look for contradictions and inconsistencies free from the bias of any algorithm, government, or external bots.</p>
<p>For people to trust their personal media, they must trust their personal AI.</p>
<h1>Open Source AI</h1>
<p>No one will ever fully trust a black box AI, built behind closed doors. No matter how successful our audits, no matter how trusted our government oversight, we will never fully trust these machines to be our closest confidants in matters of governance if we can’t trust how they were built.</p>
<p>We need open source AI. Not just open weight AI, we need to see every detail of the data and process that created the AI, so that individually, or in aggregate as a community, we can vet the creation of the AI.</p>
<p>The open source AI doesn’t need to be as powerful as closed AIs. In fact it likely shouldn’t be. It shouldn’t be so powerful that it can build weapons of mass destruction, or hack into secure computer systems. But it should be powerful enough to reason well, and help people digest the deluge of information necessary to be an informed citizen.</p>
<p>We already see a strong capable open source AI today. And, exactly as needed, it is less capable than the most powerful AIs we are beginning to use to run our government, while still being powerful enough to help the needs of individual people. We should invest in continuing this trend, while finding ways to safeguard against open source AI getting dangerous military capabilities.</p>
<p>To empower people with AI we need more than open source AI though. Every citizen will need the most important resource in the world: compute.</p>
<h1>Your computational birthright</h1>
<p>The most important asset we have is our brain. With it we can work a job, build a company, or run for Congress. It sounds silly and obvious, but this is a powerful fact: Every person has a brain. And the brain is today the most powerful computer in the universe.</p>
<p>Tomorrow it will be obsolete.</p>
<p>Intelligence is the most powerful force in the world. Part of what balances the power of the world is that each of us has a supercomputer in our head, powering our intelligence.</p>
<p>To maintain a balanced world, everyone should have their fair share of intelligence. We could instead gift everyone money via a Universal Basic Income (UBI). But it’s unclear money will have meaning soon. And it’s unclear further if anyone can retain meaning if they’re dependent on UBI.</p>
<p>Instead, let’s ensure that tomorrow people have what they are born with today: a computer as great as any other. This would take the form of a guaranteed compute budget, for every person. A computational birthright.</p>
<p>This compute must be non-transferable. Today, you can <em>temporarily</em> decide to use the computer in your head to benefit others, such as your employer. But you cannot enter into a contract that would make that permanent. You aren’t allowed to sell yourself into slavery. Likewise, tomorrow, your sovereignty as a citizen of the future will be predicated on your compute birthright, which must be inviolable and bound permanently to you as a person.</p>
<p>This of course has its own requirement: energy. And growth.</p>
<h1>Energy today</h1>
<p>Compute is ultimately just a form of energy. Without rapidly expanding energy sources, we will be forced to make extremely hard tradeoffs on what to compute, especially if we face geopolitical adversaries that may unilaterally redeploy all of their compute toward military ends.</p>
<p>We must have so much compute that we can build a worthy future, while having so much to spare that we can defend it. This means radically accelerating our domestic energy investments.</p>
<p>But even still, we’ve seen that an automated dictatorship could outstrip our own energy if they are ruthless enough with their domestic policy. And they very well might be. We thus need even more energy. More energy than exists or can exist for any nation on Earth.</p>
<p><div class="image-container"><img alt="Image from Google Doc" class="doc-image" src="images/1vpDT4RJpSOw_vdGMdIv52l1zW7flywl9oqSMm6yPTW8_None.png"/></div></p>
<h1>A shared prize</h1>
<p>There’s only one place that has the extreme energy we demand: space.</p>
<p>The sun emits almost a million, trillion gigawatts of power. 3.8 × 10^26 watts. Almost a billion gigawatts for every human alive today. It radiates out into the vastness of interstellar space, wasted forever.</p>
<p>There is very simple technology to capture it. Solar panels. What we need is to make them at scale, which requires automation, which is luckily exactly the extreme force that is entering the world at this moment and causing our existential problems. Once again, automation is the key to solving the problems introduced by automation. We need energy — all of it. Automation can deliver it.</p>
<p>Capturing the entire output of the sun may take longer than we have, but there is a stepping stone that still alleviates most of our energy pressure: the moon. With 10 million gigawatts of solar flux, it still vastly outclasses the energy ceiling of any nation on Earth. And the lunar regolith that makes up the moon’s surface is more than 20% silicon. We can harvest the needed silicon by simply scooping up the loose lunar surface.</p>
<p>Even this is, of course, an extremely ambitious goal. But it’s exactly the type of extreme windfall that strong AI will deliver. And the energy and compute the moon can deliver will multiply the output of AI a million fold further. Moreover, it’s a shared resource that is not easy to replicate. Today, the AI arms race is competitive, no one has a decisive lead. The inputs to build AI are surprisingly easy to obtain: data, which is abundant on the internet, and computers, created by one of the most highly scaled industries in human history. But there is only one moon, and it’s not easy to reach.</p>
<p>That could make it a decisive high ground for the free world.</p>
<p>And with that high ground, we can promise to share its wealth with everyone, including the power hungry would-be dictators. We can bring them to the world table by offering them bounty they couldn’t achieve if they instead seized power of their nation. Just like today, where the rich in the free world live better than dictators, we can set the incentives so the same is true tomorrow. So that even for those among us who seek power —and there are many— even then it’s in their best interest to cooperate within a free society, to enjoy the ever greater bounties of the universe.</p>
<h1>The AI-powered Judiciary</h1>
<p>You thought I forgot about the Judiciary, but I snuck it in at the bottom here as a bookend. By default the Executive will be automated, so we must sandwich it with an AI-powered Legislature and an AI-powered Judiciary. This is the only way to ensure a future of checks and balances. The only way to ensure government stays democratic, in check, at the service of all of us. For the people, even when it’s no longer strictly of the people.</p>
<p>We must ultimately seek not just exceptional intelligence, in the form of AI machines, we must seek exceptional wisdom, in the form of a human-machine civilization. The Judiciary must reflect the highest form of this goal.</p>
<p>While all three branches of government were designed to be co-equal, the Executive has crept up to become the dominant branch. As a practical point, we should first upgrade the Legislature and Judiciary with AI, or we risk an overpowered Executive. With no change in course, however, it’s the Executive that will embrace AI first, further disrupting the balance of power.</p>

        </div>
    </div>
</body>
</html>