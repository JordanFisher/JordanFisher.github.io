<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>By any other name</title>
    <style>
        /* Define a variable for the font size */
        :root {
            --font-size: 1.25rem;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            color: #1a1a1a;
            background-color: #ffffff;
            padding: 1rem;
        }
        
        a {
            color: #0066cc;
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: border-bottom-color 0.2s ease-in-out;
        }
        
        a:hover {
            border-bottom-color: #0066cc;
        }

        .container {
            max-width: 38em;
            margin: 0 auto;
            padding: 1rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-top: 3.95rem;
            margin-bottom: 1.5rem;
            line-height: 1.2;
        }
        
        h1.title-header {
            font-size: 2.5rem;
            margin-top: 6.85rem;
            margin-bottom: 2rem;
            line-height: 1.2;
        }

        #story p {
            font-size: var(--font-size);
            margin-bottom: 1.5rem;
        }

        /* Description styling */
        .description-block {
            font-size: var(--font-size);
            margin: 2rem 0;
            padding: 1.5rem;
            border-left: 4px solid #ccc;
            background-color: #f9f9f9;
            font-style: italic;
        }

        .description-block p {
            margin-bottom: 1rem;
        }

        .description-block p:last-child {
            margin-bottom: 0;
        }
        
        @media (prefers-color-scheme: dark) {
            .description-block {
                background-color: #2a2a2a;
                border-left-color: #555;
            }
        }
        
        /* List styling */
        #story ul, #story ol {
            font-size: var(--font-size);
            margin-bottom: 1.5rem;
            margin-left: 2rem;
        }
        
        /* All list items get the same spacing */
        #story li {
            margin-bottom: 0.65rem;
        }
        
        /* Add more space after a list ends inside a top-level list item */
        #story > ul > li > ul,
        #story > ul > li > ol,
        #story > ol > li > ul,
        #story > ol > li > ol {
            margin-bottom: 0.9rem;
        }

        /* Nested lists styling */
        #story ul ul, 
        #story ul ol,
        #story ol ul,
        #story ol ol {
            margin-top: 0.5rem;
            margin-bottom: 1.6rem;
        }
        
        /* Image styling */
        .image-container {
            margin: 2rem 0;
            text-align: center;
        }
        
        .doc-image {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        
        .image-caption {
            font-size: 0.9rem;
            margin-top: 0.5rem;
            color: #666;
            font-style: italic;
            text-align: center;
        }
        
        @media (prefers-color-scheme: dark) {
            .image-caption {
                color: #aaa;
            }
        }

        @media (prefers-color-scheme: dark) {
            body {
                background-color: #1a1a1a;
                color: #f0f0f0;
            }
            
            a {
                color: #5abbff;
            }
            
            a:hover {
                border-bottom-color: #5abbff;
            }
        }

        /* Back link styling */
        .back-link {
            margin-top: 3rem;
            margin-bottom: 2rem;
            font-size: 1.1rem;
        }
        
        .back-link a {
            padding: 0.5rem 0;
            display: inline-block;
        }

        @media (max-width: 600px) {
            body {
                padding: 0.5rem;
            }

            .container {
                padding: 0.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            #story p, 
            #story ul,
            #story ol {
                font-size: var(--font-size);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="story">

<h1 class="title-header">By any other name</h1><div class="description-block"><p>Removing implicit guardrails will have many effects. Let’s focus specifically on how it removes impediments to concentration of power.</p></div>
<p>Removing implicit guardrails will have many effects, but let’s focus specifically on how it removes impediments to concentration of power.</p>
<p>Throughout history there have been natural impediments to tyranny. Communication, to start with. It’s damn hard to control a sprawling empire when it takes months to communicate across it. When the Mongols conquered the known world, or when Alexander did it, the outcome was short-lived.</p>
<p>“Heaven is high, and the emperor is far away.”</p>
<p>It’s impossible to forever subjugate a people that is far away.</p>
<p>Even today, the emperor is far. In a country of hundreds of millions or even billions, your text message to a friend will likely go unnoticed, even if you’re coordinating a protest. Even if you’re coordinating <em>a riot</em>. Finding your text message among billions is harder than finding a needle in a haystack. This is a strong limit on the central power of governments.</p>
<p>But there are stronger limits.</p>
<p>The government itself is run by its own citizens, and they have moral thresholds they won’t cross. Those thresholds are fuzzy, and leaders will constantly test them, unsure what the full extent of their power is before they’re rejected. They have to do this cautiously; it’s hard to regain a mandate after you’ve lost it. Implicitly, a country is run not just by its citizen-powered government, but by society writ large: by millions of human powered companies, human powered social groups, and human powered discussions that influence the power dynamic of both public and private forces.</p>
<p>The ultimate limit on dictatorship though is abundance. The rich in America live better lives than Kim Jong Un. They enjoy all the material benefits he does, without the fear of assassination or coups or the stress of managing international geopolitics. What rich person would trade spots with a dictator?</p>
<p>The abundance created in prospering democracies provides the biggest incentives for leaders to maintain it. If you successfully seize power, you’ll at best become a lord of shit. In illiberal dictatorships, the best and brightest flee or, if they stay, build less, discover less, create less. What remains for the dictator is a life impoverished, worse than an average upper class life in America.</p>
<p>AI removes all of these implicit impediments <em>and also adds explicit accelerants toward tyranny.</em></p>
<p>Concretely:</p>
<ul>
<li>A fully automated government can persecute with impunity, with no moral pushback? from individual human agents.</li>
<li>An automated FBI can fabricate infinite evidence against millions of adversaries, without a single human agent to say no or to blow the whistle.</li>
<li>An automated justice department can prosecute millions of cases against citizens brought by this automated FBI.</li>
<li>Automated intelligence agencies can review every text message, every email, and every social media post. With superintelligent computer hacking abilities, they can access all information not defended by similarly powerful superintelligences. Even today, nation states can hack almost any target they want, but at a high human cost. Tomorrow, with this process automated, the expensive tools they reserved for fighting grave national security risks can cheaply be turned to monitor and exploit every citizen.</li>
<li>An automated system can further weave all of this complex information together into a single map of the entire population, understanding where and how to exert pressure to further consolidate control over individuals.</li>
<li>These are all powers that the government has today, but that tomorrow will suddenly become cheap enough to do at scale, and will be automated enough to do without any human agents in the government (if any remain) able to stop it</li>
</ul>
<p>Worse, even without a thirst for power, leaders will be pressured to move toward this world.</p>
<p>Everyone wants more efficient government, so we will increasingly install automation in government agencies. Corporations will (and are) rapidly pushing for their own internal automation; they <em>have to</em> in order to stay competitive. And there will be strong lobbying from corporations to remove blockers toward automation: they do and will argue that this is necessary for their businesses to stay viable. And in a global economy, they’re right.</p>
<p>Likewise, governments will have to automate to stay competitive against foreign adversaries. A human powered intelligence organization will be helpless against a foreign intelligence organization fully automated and powered by superintelligence.</p>
<p>There will be intense pressure to allow organizations to fully automate. Once they do, fully automated entities will outcompete non-automated entities. The remaining battle for power will be between automated powers, and in an automated world little else matters in the outcome of those battles beyond the scale of each power. Today economic and military battles are won by a combination of scale <em>and also</em> talent, morale, and culture. Tomorrow, the human elements will be removed, and scale and position alone will dictate how showdowns resolve. Power will beget power, with no natural limit.</p>
<p>Without new guardrails in place to mitigate this runaway effect, the default outcome is centralization of power. The competitive landscape will force it. Then, whoever wields that central power can easily choose to solidify it into a dictatorship. But will they? If they are self interested, yes. Unlike the dictatorships of today that decrease abundance, even for the leaders, an automated dictatorship of tomorrow will likely create more abundance for the dictator than if they don’t seize power:</p>
<p>A fully automated economy will require no further input from humans. Therefore, there is no implicit need for citizens to help push the economy forward. Worse still, allowing multiple winners in the economy is no longer needed, and is strictly a net-negative for anyone in control. Today, the spoils of the economy must at least partially be spread out, to keep the wheels of the economy spinning and the luxuries of abundance available to leaders. But a fully automated economy can be owned by a single person and yield them more wealth than they could ever obtain in a free society, even a free society powered by AI.</p>
<p>But there is an <em>even greater</em> force at play: automated dictatorships will likely be more powerful than automated democracies, all other things equal.</p>
<p>Even with exponentially growing compute, there will be strong limits on the amount of compute at any time. In a world where you can turn compute into intelligence, compute will be the key ingredient for all goals. Why does this create a disadvantage for free societies?</p>
<p>A free society will in some part distribute their compute across millions of needs: in fact, we are already seeing this today. Today, vast numbers of GPUs are dedicated to serving the requests of individual people via Claude, ChatGPT, and Gemini. At the business level, an equal number of chips are earmarked for powering SaaS businesses and transforming existing enterprises. Some compute is spent on curing diseases, of which there are thousands. The US has 340 million people. If each person has needs that can be met by a single GPU, we will need to build 340 million GPUs before they are satiated (and likely they won’t be, there will be things we want as individuals that require 10 GPUs, 100 GPUs, and eventually more).</p>
<p>An automated dictatorship can redeploy those 340 million GPUs for singular purposes. Once AI can do research, a dictator can direct all GPUs toward researching weapons to defeat their geopolitical adversaries, including both kinetic weapons, cyber weapons, and weapons of misinformation and cultural manipulation. Ultimately, the easiest recourse for a dictator to maintain power might be to simply eradicate all other humans by engineering thousands of novel viruses at once. A free society that is distributing its compute among its citizens and industries will be at an extreme disadvantage against this.</p>
<p>Even if the technology of defense and offense are balanced in this future world, the free society will need comparable amounts of compute dedicated to defense, which may be untenable politically when no threat is immediately seen. When the threat is finally seen, any response might be too slow. In an automated world, it may be that no amount of internal spying or intelligence can tell you what’s happening inside the mind of an adversary’s superintelligence to give you forewarning. This will amplify paranoia and make defense investments more existential.</p>
<p>Beyond redirecting compute, a dictatorship can redirect <em>energy</em>, which is the final limiter of compute. Even a small dictatorship like North Korea has ~10 gigawatts of capacity, enough to power millions of GPUs, far more than our biggest compute clusters today. But doing so would require the unthinkable: depriving the citizens of North Korea of necessary energy in order to feed industry instead. Is even a dictator like Kim Jong Un heartless enough to make this trade?</p>
<p>Yes.</p>
<p>Only half of North Koreans have access to electricity today, and those that do are often limited to 2 hours a day. There is enough energy for all North Koreans, but most is instead exported for profit or used for industry to power the regime. This is the reality today. Tomorrow, the allure of redirecting electricity will be even stronger.</p>
<p>The US has 100x the energy of North Korea. Many countries have 10x or more. These could be redirected for even more staggering amounts of compute, and hence capabilities. Most countries can grow energy only at a few percent per year, even the US. It is exceptionally faster to simply redirect all civilian energy.</p>
<p>Even in liberal democracies there is precedent for rationing civilian resources when faced with total war.</p>
<p>But available energy won’t be a static variable, it will grow, and a dictatorship can grow it faster. If North Korea is willing to further disadvantage its citizens (which it likely will, if it has access to full automation and no longer needs its citizens), it can generate 3,800 gigawatts by covering its country in solar panels, yielding 3x the energy of the United States. By disregarding human needs, even a small player like North Korea can drastically outclass the fractured output of the most powerful free society. The US will, of course, continue to build more power plants. But in order to credibly outstrip the power of a full throttled automated dictatorship, it would need to seriously disrupt its own citizens.</p>
<p><div class="image-container"><img alt="Image from Google Doc" class="doc-image" src="images/1zyN6ZNIWZx3qaPK3PPOd7H8wyW_LsxytOD7t7T8OTag_None.png"/></div></p>
<p>Everything we’ve learned from AI is that <em>the curves don’t bend.</em> Even as one AI scaling paradigm has seen diminishing returns (pretraining), new paradigms have opened up and continued to scale (post-training and Reinforcement Learning). More compute yields more capabilities, for whichever task you care about. If that task is military, more compute will give you better military capabilities than less compute. And there will be no limit to <em>how much</em>, whether or not we eventually see diminishing returns. There is a near infinite amount of things to deploy fully general AI toward. Just like a larger country can often achieve more than a smaller country, having more power will effectively mean you have more automated labor. More will be more.</p>
<p>Thus, a rational free society will be forced to consolidate its own power to defend itself. It will then be at risk of handing the ready-made lever of power over to individual leaders. Will those leaders use that power for good? The resiliency of democracy has come not from picking noble leaders. It has come from creating structures that are immune to would-be tyrants, even when we elect them. This new world doesn’t have that immunity.</p>
<p>Even if a freely elected leader means well, if they consolidate power to defend their nation, if they redirect nearly all resources to maintain the ability for their nation to survive, what is left? Tyranny by any other name would still smell like shit.</p>
<p>It’s not just that AI suddenly makes a durable dictatorship <em>possible</em>, it suddenly makes it <em>the default outcome</em>. The thirst for power has always existed, and many have tried and succeeded at building temporary dictatorships. Suddenly, with AI, the path to dictatorship will become much easier <em>and also more rewarding than any other possibility</em>. We have to expect that on net the risk of dictatorship rises substantially in the coming years.</p>
<p>The best predictor of human behavior is incentives, and the incentives are quickly transmuting for leaders into a single direction: consolidate power. We can resist this incredible force only if we build checks and balances into our governance that are amplified by AI, not subverted by it. We can do this if we try. We can do this if we recognize the risk.</p>
<p>As I write this today, we are doing neither.</p>

        </div>
        <div class="back-link">
            <a href="/">&larr; Back</a>
        </div>
    </div>
</body>
</html>