Liberty by Design

[[[There are many important conversations happening about AI. But we are missing one of the most important: how must we upgrade democracy in the age of AI if we want to keep our freedom?]]]


Welcome to the curve

AI will soon disrupt every foundation our society is built upon. If we want to control our future, there are many questions to answer. In this work we’ll focus on how our human governance needs to adjust to a world fully powered by machines. But there are many other important questions we won’t address. Two of those questions are particularly important:

Can we determine how to maintain control over AIs that are smarter than us? And can we ensure companies and nations build AI responsibly, so that only safe AIs are built?

The first question is studied in the field of AI Alignment:

Today, we don’t know how AIs work. Many prominent leaders building the most advanced AIs think we will have AI greater than all of humanity combined by the end of the decade. We don’t yet know how we’ll control AI once it exceeds us, and time is short.

The second question is explored in the field of AI Policy:

In order to be first, a company building AI may cut corners and take on more risk than the rest of humanity might like. AI Policy seeks to set the regulations and incentives such that we prevent these types of decisions. And the race doesn’t just exist between AI companies, it also exists between nations. The US and China are already racing to be first to create powerful AI. The future balance of geopolitical power may lie in the outcome. AI Policy seeks to ensure both that the race is won by democratic countries, but also to defuse the race and allow for international collaboration toward safe outcomes.

How do we solve AI Alignment? What AI Policies will push us to build aligned AIs? These are two incredibly important, unanswered questions. If you’re interested in these, I encourage you to read and engage in these discussions. We urgently need more people helping with both.

But in this work we’ll focus on a final, third question: the question of governance of a human-machine society. While AI Policy focuses on what governance might lead to the safe creation of AI, we will focus on what governance we need after: how do we govern a world that is built on and powered exclusively by machines?

Imagine we succeed at building powerful AI. Imagine further that we succeed at ensuring it’s safe and aligned to its users. How then do we want a human-machine society to look? How should it look, to protect our freedoms and liberties?

Corporations will adopt AI to automate themselves and enhance their efficiency. Governments will do the same. In fact, this is already happening. Once this process is complete, how will we exert influence on these institutions when we are no longer the force powering them? In what ways can we upgrade these institutions so that they continue to represent us, even once we aren't embedded in them?

We'll explore this core question of governance, the extent of what's at stake, and how we might fortify democracy for the human-machine age. And we’ll analyze and discuss explicit enhancements to our checks and balances that we hope will offset the loss of implicit guardrails that currently keep democracy safe.

Our discussion will cover the following:


Machines have now reached human intelligence in many domains, and will soon surpass us in most others.
If we understand why this progress is accelerating, we will be able to better design how we want to integrate machines into human society.


Societies that allow for freedom and maximum human flourishing aren’t easy to build.
Ours took thousands of years of trial and error and is still a work in progress.
What allows a society to function depends strongly on the details of its members: us humans.


Automating our economy and government will completely change all of those details.
As those details change, all of the implicit guardrails we rely upon for checks and balances on power will be swept away.
For example, institutions often avoid illegal actions because their human employees refuse to accept grossly unethical work. Or, even if employees comply with illegal requests, human whistleblowers within the organization can alert the public to any abuses. Once an institution is fully automated, these restraints won’t exist.
If we consider the military, the human component is even more important. Most soldiers would never fire on civilians, even if faced with a direct order to do so. This limits the ability of a commander to commit atrocities or to use their troops to enact a coup. With a fully automated armed forces, a motivated commander could decide to rest power for themselves.
Today, companies, governments, and militaries all require human labor to continue functioning. Ultimate power rests with humans: if they choose to leave an institution, that institution will fail.
Once our institutions are automated, power may instead sit solely with the leaders of those institutions.


Gradually, and then all at once, we will enter a world where implicit checks on power are impotent. Will our remaining explicit checks on power be sufficient guardrails?
We’ll argue that automation will make the task of seizing power substantially easier and more rewarding.
We don’t know if our AIs will be aligned, but we already know that many human leaders are not. History is replete with leaders who seize and abuse power.
If we don’t change course, human-powered tyranny may be the default outcome of a machine-powered world. And it will be increasingly hard for us to resist this tyranny the later we act.
We must evolve our governance before strong AI arrives, or we may not have any power left as citizens to fix it after.
Humans alone won’t be able to oversee leaders empowered by AI. As it stands, whoever controls AI will control nearly everything.


The forces and incentives are already at play to further concentrate power.
We can’t predict how all those forces will play out, but we can think through different scenarios.
Here we’ll explore a short story walking down our current path, and how it leads to an unrecoverable concentration of power and the end of liberty.
The future will almost surely play out differently, in one of a million possible paths. We need to set the conditions so that the future is bright regardless of the path.


So what should we do? What should those conditions be?
How can we upgrade our society and governance to be resilient to the multitude of forces pushing us toward tyranny?
We must leverage AI itself to become part of the checks and balances on how government and industry wield AI.
Passing laws is necessary but not sufficient. An executive branch powered by superintelligence will be too strong to control if we only upgrade our laws but don’t also upgrade our oversight and enforcement.
We must enshrine the enforcement of laws inside the mechanisms of culture and government, and we must do it while we still have human-based trust in human institutions.


We should think through and imagine how things may go wrong, to better design a more resilient system.
But we should also imagine how things might go right, to ensure we’re building a future we want to live in.
Here we’ll illustrate a positive, near future by telling a short story of how things might go well, assuming we upgrade our checks and balances.
A positive future will surely play out differently than we expect, even if things go well. But we must set a vision of what good looks like so we know what we’re fighting for.
Moreover, we should plan for the worst. We should assume that one day we'll elect a would-be tyrant. The governance we design today should be so robust that even then our democracy would stand. 


The discussion around AI policy has rapidly become politically coded.
Adopting all the policies of the left, or all of the policies of the right, will likely lead to disaster.
If we only regulate and slow down AI, we will cede the race to China.
If we only automate our military and the executive branch, without also upgrading our checks and balances, we will hand so much power over to our leaders that we may never be free again.
Instead, we must modernize our government and military to remain the dominant superpower, and we must simultaneously upgrade the oversight and safeguards that prevent abuse of this incredible concentration of power.
And while we must treat the race against China as existential, we must also look constantly for offramps toward deescalation and international peace.


Intelligence is the most transformative power the world has ever seen. Until today, that power has been human alone. Now, with AI, we are on the precipice of unleashing that power a thousand fold, and it won’t be human.
The force of multiplied intelligence completely rewrites the rules of our world. With it we may see near infinite abundance, or total ruin.
We are on the exponential now. Where will it take us? We must decide together.
AI is the defining event of our lifetime, but the outcome is not yet written. We all own the conversation for what we want the future to be.
If we don’t together lead this debate —all of us— then the most important decisions of the future of our world will be made without us.

But, if we begin this great debate today, we can set the framework for a positive future.

TABLEOFCONTENTS









